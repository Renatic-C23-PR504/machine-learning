{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CBQIfDHLIsZ",
        "outputId": "af7bde79-ee25-4857-93de-dc9d88979f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import tensorflow as tf\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "validation_dir = os.path.join(data_dir, 'validation')\n",
        "testing_dir = os.path.join(data_dir, 'testing')"
      ],
      "metadata": {
        "id": "31_y55YVPYGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/dataset/testing/testing_noneye'  # Replace with the path to your dataset directory in Google Drive\n",
        "\n",
        "# Get the list of image files in the dataset directory\n",
        "image_files = os.listdir(dataset_path)\n",
        "\n",
        "# Count the number of image files\n",
        "num_images = len(image_files)\n",
        "\n",
        "# Print the number of images\n",
        "print(f\"Number of images: {num_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqThotu9XfMG",
        "outputId": "3494b70b-9204-4bad-db4a-1297453d8c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size = (150,150)\n",
        "batch_size = 256\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.25,\n",
        "    zoom_range=0.25,\n",
        "    rotation_range = 45,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        "    )\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = False\n",
        "    )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    testing_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = False\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFp1ivMHRAIW",
        "outputId": "1809b52f-27cc-4a9c-ec56-b77cc7d51c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4556 images belonging to 2 classes.\n",
            "Found 567 images belonging to 2 classes.\n",
            "Found 568 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xHuBbrlYYmN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        ")\n",
        "\n",
        "# Access the accuracy and validation accuracy from the history object\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGZhRwF7aU3n",
        "outputId": "77581549-468f-46f7-f937-3e4e4ad3aca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 292s 16s/step - loss: 0.3677 - accuracy: 0.8593 - val_loss: 0.0285 - val_accuracy: 0.9929\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 281s 15s/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 300s 17s/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0191 - val_accuracy: 0.9947\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 292s 16s/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0080 - val_accuracy: 0.9982\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 291s 16s/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 285s 16s/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0130 - val_accuracy: 0.9965\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 300s 17s/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.0191 - val_accuracy: 0.9965\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 283s 16s/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 293s 16s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0125 - val_accuracy: 0.9982\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 283s 16s/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0201 - val_accuracy: 0.9947\n"
          ]
        }
      ]
    }
  ]
}